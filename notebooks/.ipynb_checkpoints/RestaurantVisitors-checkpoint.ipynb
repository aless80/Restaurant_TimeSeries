{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast restaurant visits for establishments in Japan based on historical visits and reservation data from two websites - Hot Pepper Gourmet and AirREGI. We are also given some additional metadata on the restaurants such as genre and location. Find the competition at [kaggle](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>.container { width:90% !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "    <style>.container { width:90% !important;} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and preprocessing data  \n",
    "Taken from [this kernel](https://www.kaggle.com/the1owl/surprise-me/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data[ar]:       (air_reserve, hpg_reserve)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  reserve_datetime_diff  reserve_visitors\n",
       "0  air_00a91d42b08b08d9  2016-10-31                      0                 2\n",
       "1  air_00a91d42b08b08d9  2016-12-05                      4                 9\n",
       "2  air_00a91d42b08b08d9  2016-12-14                      6                18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data[hr]:       (air_reserve, hpg_reserve)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  reserve_datetime_diff  reserve_visitors\n",
       "0  air_00a91d42b08b08d9  2016-01-14                      3                 2\n",
       "1  air_00a91d42b08b08d9  2016-01-15                      6                 4\n",
       "2  air_00a91d42b08b08d9  2016-01-16                      3                 2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data['tes']        (sample_submission)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors  visit_date  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0  2017-04-23   \n",
       "1  air_00a91d42b08b08d9_2017-04-24         0  2017-04-24   \n",
       "2  air_00a91d42b08b08d9_2017-04-25         0  2017-04-25   \n",
       "\n",
       "           air_store_id  dow  year  month  \n",
       "0  air_00a91d42b08b08d9    6  2017      4  \n",
       "1  air_00a91d42b08b08d9    0  2017      4  \n",
       "2  air_00a91d42b08b08d9    1  2017      4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stores so far:     (unique resto's from sample_submission)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow\n",
       "0  air_00a91d42b08b08d9    0\n",
       "1  air_0164b9927d20bcc3    0\n",
       "2  air_0241aa3964b7f861    0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../input/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../input/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../input/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../input/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "#Work on reservations (air_reserve and hpg_reserve)\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - \n",
    "                                                                  r['reserve_datetime']).days, axis=1)\n",
    "    data[df] = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', \n",
    "                                    'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date'})\n",
    "    print \"\\ndata[\"+df+\"]:       (air_reserve, hpg_reserve)\"\n",
    "    data[df].head(3)\n",
    "\n",
    "#Submission file is  id,visitors air_00a91d42b08b08d9_2017-04-23,0\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "print \"data['tes']        (sample_submission)\"\n",
    "data['tes'].head(3)\n",
    "#From submission get resto's\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) \n",
    "                    for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "print \"\\nstores so far:     (unique resto's from sample_submission)\"\n",
    "stores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data['tra']:      (air_visit_data)\n",
      "           air_store_id  visit_date  visitors  dow  year  month\n",
      "0  air_ba937bf13d40fb24  2016-01-13        25    2  2016      1\n",
      "1  air_ba937bf13d40fb24  2016-01-14        32    3  2016      1\n",
      "2  air_ba937bf13d40fb24  2016-01-15        29    4  2016      1\n",
      "\n",
      "stores:          (unique resto's from sample_submission + tra/air_visit_data + as/air_store_info)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.920635</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>139.779996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  min_visitors  mean_visitors  median_visitors  \\\n",
       "0  air_00a91d42b08b08d9    0           1.0      22.457143             19.0   \n",
       "1  air_0164b9927d20bcc3    0           2.0       7.500000              6.0   \n",
       "2  air_0241aa3964b7f861    0           2.0       8.920635              8.0   \n",
       "\n",
       "   max_visitors  count_observations  air_genre_name  air_area_name   latitude  \\\n",
       "0          47.0                35.0               6             44  35.694003   \n",
       "1          19.0                20.0               6             62  35.658068   \n",
       "2          23.0                63.0               7             82  35.712607   \n",
       "\n",
       "    longitude  \n",
       "0  139.753595  \n",
       "1  139.751599  \n",
       "2  139.779996  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train/test:          (visits, holidays, stores)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_datetime_diff_x</th>\n",
       "      <th>reserve_visitors_x</th>\n",
       "      <th>reserve_datetime_diff_y</th>\n",
       "      <th>reserve_visitors_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "      <td>252108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.973761</td>\n",
       "      <td>3.019678</td>\n",
       "      <td>2016.307697</td>\n",
       "      <td>6.208200</td>\n",
       "      <td>2.987228</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>5.305171</td>\n",
       "      <td>20.816460</td>\n",
       "      <td>19.687483</td>\n",
       "      <td>49.308634</td>\n",
       "      <td>50.030304</td>\n",
       "      <td>5.237977</td>\n",
       "      <td>49.794913</td>\n",
       "      <td>35.368196</td>\n",
       "      <td>136.460923</td>\n",
       "      <td>1.496033</td>\n",
       "      <td>0.642074</td>\n",
       "      <td>-0.379587</td>\n",
       "      <td>-0.580588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.757007</td>\n",
       "      <td>1.923985</td>\n",
       "      <td>0.461542</td>\n",
       "      <td>3.680263</td>\n",
       "      <td>2.033470</td>\n",
       "      <td>0.219329</td>\n",
       "      <td>6.364927</td>\n",
       "      <td>12.659500</td>\n",
       "      <td>12.784121</td>\n",
       "      <td>37.029759</td>\n",
       "      <td>14.631451</td>\n",
       "      <td>3.155539</td>\n",
       "      <td>30.804083</td>\n",
       "      <td>3.570526</td>\n",
       "      <td>11.707118</td>\n",
       "      <td>155.733715</td>\n",
       "      <td>7.401552</td>\n",
       "      <td>4.747227</td>\n",
       "      <td>2.504373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.016667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34.688241</td>\n",
       "      <td>135.265455</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.256410</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.669361</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>28.058824</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>877.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>147.428571</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>877.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>44.020632</td>\n",
       "      <td>144.273398</td>\n",
       "      <td>67801.000000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            visitors            dow           year          month  \\\n",
       "count  252108.000000  252108.000000  252108.000000  252108.000000   \n",
       "mean       20.973761       3.019678    2016.307697       6.208200   \n",
       "std        16.757007       1.923985       0.461542       3.680263   \n",
       "min         1.000000       0.000000    2016.000000       1.000000   \n",
       "25%         9.000000       1.000000    2016.000000       3.000000   \n",
       "50%        17.000000       3.000000    2016.000000       7.000000   \n",
       "75%        29.000000       5.000000    2017.000000      10.000000   \n",
       "max       877.000000       6.000000    2017.000000      12.000000   \n",
       "\n",
       "         day_of_week    holiday_flg   min_visitors  mean_visitors  \\\n",
       "count  252108.000000  252108.000000  252108.000000  252108.000000   \n",
       "mean        2.987228       0.050673       5.305171      20.816460   \n",
       "std         2.033470       0.219329       6.364927      12.659500   \n",
       "min         0.000000       0.000000      -1.000000      -1.000000   \n",
       "25%         1.000000       0.000000       1.000000      11.016667   \n",
       "50%         3.000000       0.000000       3.000000      18.256410   \n",
       "75%         5.000000       0.000000       7.000000      28.058824   \n",
       "max         6.000000       1.000000     132.000000     147.428571   \n",
       "\n",
       "       median_visitors   max_visitors  count_observations  air_genre_name  \\\n",
       "count    252108.000000  252108.000000       252108.000000   252108.000000   \n",
       "mean         19.687483      49.308634           50.030304        5.237977   \n",
       "std          12.784121      37.029759           14.631451        3.155539   \n",
       "min          -1.000000      -1.000000           -1.000000       -1.000000   \n",
       "25%          10.000000      28.000000           40.000000        2.000000   \n",
       "50%          17.000000      43.000000           43.000000        6.000000   \n",
       "75%          27.000000      62.000000           65.000000        7.000000   \n",
       "max         152.000000     877.000000           69.000000       13.000000   \n",
       "\n",
       "       air_area_name       latitude      longitude  reserve_datetime_diff_x  \\\n",
       "count  252108.000000  252108.000000  252108.000000            252108.000000   \n",
       "mean       49.794913      35.368196     136.460923                 1.496033   \n",
       "std        30.804083       3.570526      11.707118               155.733715   \n",
       "min        -1.000000      -1.000000      -1.000000                -1.000000   \n",
       "25%        23.000000      34.688241     135.265455                -1.000000   \n",
       "50%        55.000000      35.658068     139.669361                -1.000000   \n",
       "75%        74.000000      35.694003     139.751599                -1.000000   \n",
       "max       102.000000      44.020632     144.273398             67801.000000   \n",
       "\n",
       "       reserve_visitors_x  reserve_datetime_diff_y  reserve_visitors_y  \n",
       "count       252108.000000            252108.000000       252108.000000  \n",
       "mean             0.642074                -0.379587           -0.580588  \n",
       "std              7.401552                 4.747227            2.504373  \n",
       "min             -1.000000                -1.000000           -1.000000  \n",
       "25%             -1.000000                -1.000000           -1.000000  \n",
       "50%             -1.000000                -1.000000           -1.000000  \n",
       "75%             -1.000000                -1.000000           -1.000000  \n",
       "max           1633.000000               626.000000          157.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_datetime_diff_x</th>\n",
       "      <th>reserve_visitors_x</th>\n",
       "      <th>reserve_datetime_diff_y</th>\n",
       "      <th>reserve_visitors_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  dow  year  month  day_of_week  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25    2  2016      1            6   \n",
       "1  air_ba937bf13d40fb24  2016-01-14        32    3  2016      1            4   \n",
       "2  air_ba937bf13d40fb24  2016-01-15        29    4  2016      1            0   \n",
       "\n",
       "   holiday_flg  min_visitors  mean_visitors         ...          max_visitors  \\\n",
       "0            0           7.0      23.843750         ...                  57.0   \n",
       "1            0           2.0      20.292308         ...                  54.0   \n",
       "2            0           4.0      34.738462         ...                  61.0   \n",
       "\n",
       "   count_observations  air_genre_name  air_area_name   latitude   longitude  \\\n",
       "0                64.0             4.0           62.0  35.658068  139.751599   \n",
       "1                65.0             4.0           62.0  35.658068  139.751599   \n",
       "2                65.0             4.0           62.0  35.658068  139.751599   \n",
       "\n",
       "   reserve_datetime_diff_x  reserve_visitors_x  reserve_datetime_diff_y  \\\n",
       "0                     -1.0                -1.0                     -1.0   \n",
       "1                     -1.0                -1.0                     -1.0   \n",
       "2                     -1.0                -1.0                     -1.0   \n",
       "\n",
       "   reserve_visitors_y  \n",
       "0                -1.0  \n",
       "1                -1.0  \n",
       "2                -1.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Work on historical visit data for the air restaurants (air_visit_data)\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "print \"data['tra']:      (air_visit_data)\"\n",
    "print data['tra'].head(3)\n",
    "#Add columns with visit info to stores\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "#Join stores and air_store_info (ir_genre_name  air_area_name  latitude  longitude)\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) #join stores and air_store_info.csv on id\n",
    "print \"\\nstores:          (unique resto's from sample_submission + tra/air_visit_data + as/air_store_info)\"\n",
    "#stores.head(3)\n",
    "#Encode string columns in stores (air_genre_name, air_area_name)\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "stores.head(3)\n",
    "\n",
    "#Work on holidays\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "\n",
    "#Create train/test = visits (tra/tes) + holidays + stores (incl genre, area data) + air/pgh reservations\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "#Train = joint visits with stores on id and day of week\n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "col = [c for c in train if c not in ['id', 'air_store_id','visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "print \"\\ntrain/test:          (visits, holidays, stores)\"\n",
    "train.describe()\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of data  \n",
    "**stores** contains 821 resto's, it does not contain dates which are in 'tra'/'tes' reservations. Store contain stats on visitors per day of week, plus genre, area data.  \n",
    "**train/test** = visits (tra/tes) + holidays + stores (incl genre, area data) + air/pgh reservations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and prediction\n",
    "The source above fits Linear Regression and an extra-trees regressor.  \n",
    "The following predicts and evaluates score on the same samples the model was trained on. It may over fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=4,\n",
       "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "          n_estimators=200, n_jobs=-1, oob_score=False, random_state=3,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RMSE LinearRegressor: ', 0.55513839010642696)\n",
      "('RMSE ExtraTreesRegressor: ', 0.53286668803419068)\n"
     ]
    }
   ],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "\n",
    "lr = linear_model.LinearRegression(n_jobs=-1)\n",
    "etc = ensemble.ExtraTreesRegressor(n_estimators=200, max_depth=4, n_jobs=-1, random_state=3)\n",
    "lr.fit(train[col], np.log1p(train['visitors'].values))\n",
    "etc.fit(train[col], np.log1p(train['visitors'].values))\n",
    "print('RMSE LinearRegressor: ', RMSLE(np.log1p(train['visitors'].values), lr.predict(train[col])))\n",
    "print('RMSE ExtraTreesRegressor: ', RMSLE(np.log1p(train['visitors'].values), etc.predict(train[col])))\n",
    "#('RMSE LinearRegressor: ', 0.5559363280886771) without holidays as in kernel\n",
    "#('RMSE ExtraTreesRegressor: ', 0.53254265523633648)\n",
    "test['visitors'] = (lr.predict(test[col]) * 0.5) + (etc.predict(test[col]) * 0.5)\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "#test[['id','visitors']].to_csv('lr_submission.csv', index=False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, end of the source kernel.  \n",
    "TODO: Try more regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plot visits by restaurant type and area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ./input/air_visit_data.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-820d2159dfbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./input/air_visit_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'visit_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstore_ind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#len(unique_stores) is 821\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mair_store_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0munique_stores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstore_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas-0.20.3-py2.7-linux-x86_64.egg/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas-0.20.3-py2.7-linux-x86_64.egg/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas-0.20.3-py2.7-linux-x86_64.egg/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas-0.20.3-py2.7-linux-x86_64.egg/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas-0.20.3-py2.7-linux-x86_64.egg/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File ./input/air_visit_data.csv does not exist"
     ]
    }
   ],
   "source": [
    "air = pd.read_csv('../input/air_visit_data.csv', parse_dates=[1])\n",
    "air.set_index(['visit_date'], inplace=True)\n",
    "air.index.name=None\n",
    "for store_ind in range(0,10): #len(unique_stores) is 821\n",
    "    resto = air[air.air_store_id == unique_stores[store_ind]]\n",
    "    resto.visitors.plot(figsize=(15,3),grid=True,xlim=['2016-01','2017-04'],\n",
    "                        title='Visitors in air_visit_data with id: '+air.air_store_id[store_ind])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "NB: The number of stores with reservations = nujmber of reservations because there's one reservation per store.\n",
    "    For this reason the mean is IMO a good normalized measure of visits, mean = # visits / # reserved stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "# \n",
    "air = pd.read_csv('./input/air_visit_data.csv', parse_dates=[1])\n",
    "air.set_index(['visit_date'], inplace=True)\n",
    "air.index.name=None\n",
    "air.drop('air_store_id',axis=1,inplace=True)\n",
    "df2=pd.DataFrame()\n",
    "df2['visit_total'] = air.groupby(air.index,squeeze=True,sort=True)['visitors'].sum()\n",
    "df2['visit_mean'] = air.groupby(air.index,squeeze=True,sort=True)['visitors'].mean()\n",
    "df2['reserv_cnt'] = air.groupby(air.index,squeeze=True,sort=True)['visitors'].count()\n",
    "air=df2;del df2\n",
    "\n",
    "#Get the date info with dow and holidays\n",
    "hol=pd.read_csv('./input/date_info.csv', parse_dates=True).rename(columns={'calendar_date':'visit_date'})\n",
    "hol['visit_date'] = pd.to_datetime(hol['visit_date'])\n",
    "hol.set_index(['visit_date'], inplace=True)\n",
    "hol.index.name=None\n",
    "hol.day_of_week = hol.day_of_week.apply(list(calendar.day_name).index)\n",
    "\n",
    "#Get the test submission\n",
    "test = pd.read_csv('./input/sample_submission.csv')\n",
    "test['store_id'], test['visit_date'] = test['id'].str[:20], test['id'].str[21:]\n",
    "test.set_index('visit_date',drop=True, inplace=True)\n",
    "test.index.name=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorative analysis on cumulative visits\n",
    "I create a series with cumulative visits, that is the sum of visits to all stores/restaurants. Notice the huge increase in July 2016 (see above). The drop comes because many restaurants did not have any data before that month. Probably the registration system started \"monitoring\" many new restaurants/stores in that period.  \n",
    "There is also a drop in visits and reservation counts in the beginning of the years, probably due to stores being close around new year's eve.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the cumulative visits\n",
    "air['visit_total'].plot(legend=True);\n",
    "air['reserv_cnt'].plot(legend=True,figsize=(15,4),secondary_y=True,\n",
    "                      title='Visitors total and reservation count (with holidays)');\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the sum of visits, a better measurement is **the mean** of the cumulative visits (sum of all visits divided by number of reservations or, which is the same, the number of \"active\" restaurants). The series does not show the gap in July 2016 anymore, though variance seems to become smaller for some months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "air['visit_mean'].plot(figsize=(15,4),legend=True, title='Visitors mean (with holidays)')\n",
    "air['reserv_cnt'].plot(legend=True,figsize=(15,4),secondary_y=True,title='Visitors total and reservation count (with holidays)');\n",
    "\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a seasonal decomposition using moving averages. The trend captures three peaks in the data: \n",
    "\n",
    "* Around mid-March 2016, \n",
    "* April 2016\n",
    "* Just before the drop on new year's eve 2016, \n",
    "* Again mid-March 2017 \n",
    "I see on wikipedia that these are the vernal equinox (around March 20), the golden week starting on April 29, Emperor's birthday :( on December 23rd and new year's day on January 1st, vernal equinox again.  \n",
    "This sounds great, though some other holidays are hardly visible in the data. I can imagine that people has the tendency to stay home in the winter.\n",
    "\n",
    "The season plot shows a strong weekly period where the lowest number of visit happen on Monday. Below I show that people mostly do reservations between Friday and Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm  \n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(air.visit_mean, freq=12)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=air.join(hol)\n",
    "df2[df2.holiday_flg==0].groupby(hol.day_of_week,squeeze=True,sort=True)['visit_mean'].sum()\n",
    "#df2.day_of_week=df3.day_of_week.apply(lambda x: list(calendar.day_name)[x]) # equiv to air.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-ARIMA analysis: make the series stationary\n",
    "Stationary means that variance and autocorrelation structure not changing over time.  \n",
    "Changes in mean happen when the series has a overall trend, e.g. it increases/decreasing. In that case use differentiation: create a new series y with the first difference y=x$_t$-x<sub>t-1</sub> (this is the \"I\" in ARIMA models), and take seasonal differences (which you can account for in ARIMA model).  \n",
    "Changes is variance mean that oscillations change. To fix this a log of the series compresses oscillations.  \n",
    "Changes in autocorrelation means that oscillations become broader (or narrower). If you have this I think you are screwed..\n",
    "\n",
    "The Dickey-Fuller test helps us deciding whether a series is stationary. The test's null hypothesis is that the series is non-stationary. If the Test Statistic output of the Dickey-Fuller test is less than the Critical Value, we can reject the null hypothesis and say that the series is stationary.  \n",
    "Below we notice that the original time series (using the mean of visits) is fairly stationary: Test Statistic=-3.796104 > Critical Value (1%) = -3.444615. Applying 1st or seasonal differentiation greatly improves the test results (Test Statistic = -6.608968 and 7.196314, respectively). A weekly periodic structure is clearly visible in the data, so I lean towards using seasonal differentiation. \n",
    "Takign the log of the data helps but does not seem to be a main factor in improving stationarity. This means that variance is fairly stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=12);\n",
    "    rolstd = pd.rolling_std(timeseries, window=12);\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print 'Results of Dickey-Fuller Test:'\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print dfoutput\n",
    "\n",
    "test_stationarity(air.visit_mean); #-3.796104\n",
    "# Log is a minor improvement, meaning that the variance is stable\n",
    "air.visit_mean_log= air.visit_mean.apply(lambda x: np.log(x))  \n",
    "'''test_stationarity(air.visit_mean_log) #-3.830754'''\n",
    "# Although I see no real global trend, 1st difference strongly improves stationarity\n",
    "air['visit_mean_diff'] = air.visit_mean - air.visit_mean.shift(1)  \n",
    "test_stationarity(air.visit_mean_diff.dropna(inplace=False)) #-6.608968e+00\n",
    "# Seasonal difference: take a weekly season improves stationarity even more\n",
    "air['visit_mean_seasonal'] = air.visit_mean - air.visit_mean.shift(7)\n",
    "test_stationarity(air.visit_mean_seasonal.dropna(inplace=False)) #-7.196314e+00\n",
    "# Seasonal and 1st difference is even better, but we were already well within the 1% confidence interval\n",
    "air['visit_mean_seasonal_diff'] = air.visit_mean_diff - air.visit_mean_diff.shift(7)\n",
    "test_stationarity(air.visit_mean_seasonal_diff.dropna(inplace=False)) #-9.427797e+00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mmm, let's stick to the seasonal series with no 1st difference. \n",
    "\n",
    "Let's run autocorrelation ACF and partial autocorrelation PACF for find the details fo the model. I will use the guidelines [here](http://people.duke.edu/~rnau/arimrule.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following ACF on the mean visits has a repeated pattern. That's our 7-day seasonal term. I should add to the model seasonal differenciation in the term **seasonal\\_order=( , 1, ,7)**.  \n",
    "If ACF was positive and decreasing over time, the series would be the typical candidate for applying 1st difference. But not here. This confirms the observation we made on the Dickey-Fuller test where the 1st difference was more stationary but not that much. I should add a **order=( , 0, ) term** to the model. Also try a constant term **trend='c'** in the model for the non-zero mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(air.visit_mean, lags=40, alpha=.05, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(air.visit_mean, lags=40, alpha=.05, ax=ax2)\n",
    "print \"ACF and PACF of the visit mean:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the ACF of the first difference, confriming the 7-day seasonal term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(air.visit_mean_diff[1:], lags=40, alpha=.05, ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF and PACF below are plotted the seasonal difference data.\n",
    "\n",
    "The PACF of the seasonal differenced series is positive at lag=1 (the series appears slightly \"underdifferenced\"). I should probably add one AR term to the model **order=(2, , )**. Only one AR term because the term at lag=2 cuts off and enters the 95% confidence interval. \n",
    "\n",
    "As for the PACF, the ACF of the seasonal differenced series is overdifferentiated at lag = 1 and cuts off (which I looked on the internet and means \"go to zero\") at lag=2. I should probably add one MA term to the model **order=( , , 2)**.\n",
    "\n",
    "displays a sharp cutoff and/or the lag-1 autocorrelation is negative--i.e., if the series appears slightly \"overdifferenced\"--then consider adding an MA term to the model.\n",
    "\n",
    "\n",
    "The ACF of the differenced series is negative at lag 7, suggesting to add a seasonal MA term **seasonal\\_order=(0, , 1, 7)** to the model. This situation is likely to occur if a seasonal difference has been used, which should be done if the data has a stable and logical seasonal pattern. If the peak was positive I would have added a season AR term. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"ACF and PACF of the 7-day differenced visit mean:\"\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(air.visit_mean_seasonal[8:], lags=40, alpha=.05, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(air.visit_mean_seasonal[8:], lags=40, alpha=.05, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More things to keep in mind:  \n",
    "Rule 9: If there is a unit root in the AR part of the model--i.e., if the sum of the AR coefficients is almost exactly 1--you should reduce the number of AR terms by one and increase the order of differencing by one.  \n",
    "Rule 10: If there is a unit root in the MA part of the model--i.e., if the sum of the MA coefficients is almost exactly 1--you should reduce the number of MA terms by one and reduce the order of differencing by one.  \n",
    "Rule 11: If the long-term forecasts* appear erratic or unstable, there may be a unit root in the AR or MA coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMAX model \n",
    "[SARIMAX](http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html) = Seasonal Auto Regressive Integrated Moving Average with eXogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sklearn.metrics .mean_squared_log_error should exist but I cannot load it..\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def mean_squared_log_error(y_pred, y_true, **dict):\n",
    "    '''Assume y_true is NaN free and y_pred can have consecutive NaN in the beginning of the series'''\n",
    "    indfirst=y_pred.first_valid_index()\n",
    "    return mean_squared_error(np.log(y_true[indfirst:]+1), \n",
    "                              np.log(y_pred[indfirst:]+1) )**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(air.visit_mean, trend='c', order=(2,0,2), seasonal_order=(0,1,1,7))\n",
    "results = mod.fit()\n",
    "print results.summary()\n",
    "air['forecast'] = results.predict(start=350, end=None, dynamic=True, exog=pd.DataFrame(hol.holiday_flg[:]) )\n",
    "air[['visit_mean', 'forecast']].plot(figsize=(15, 5));\n",
    "plt.vlines(air.index[-1],13,32,color='k');\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);\n",
    "plt.title('RMSLE: %.4f'% mean_squared_log_error(air['forecast'],air.visit_mean) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding 1st order differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMAX with eXogenous dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using holidays as exogenous data is already much better, it captures the peak on new year's eve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modx = sm.tsa.statespace.SARIMAX(air.visit_mean, trend='c', exog=hol.holiday_flg[:478], order=(2,0,0), seasonal_order=(0,1,1,7))\n",
    "resultsx = modx.fit()\n",
    "print resultsx.summary()\n",
    "air['forecastx'] = resultsx.predict(start=350, end=None, dynamic=True, exog=pd.DataFrame(hol.holiday_flg[:]) )\n",
    "air[['visit_mean', 'forecastx']].plot(figsize=(15, 5));\n",
    "plt.vlines(air.index[-1],13,32,color='k');\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);\n",
    "plt.title('RMSLE: %.4f'% mean_squared_log_error(air['forecastx'],air.visit_mean) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modx2 = sm.tsa.statespace.SARIMAX(air.visit_mean, trend='c', exog=hol[:478], order=(2,0,0), seasonal_order=(0,1,1,7))\n",
    "resultsx2 = modx2.fit()\n",
    "print resultsx2.summary()\n",
    "air['forecastx2'] = resultsx2.predict(start=350, end=None, dynamic=True, exog=pd.DataFrame(hol[:]) )\n",
    "air[['visit_mean', 'forecastx2','forecastx']].plot(figsize=(15, 5));\n",
    "plt.vlines(air.index[-1],13,32,color='k');\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);\n",
    "plt.title('RMSLE: %.4f'% mean_squared_log_error(air['forecastx2'],air.visit_mean) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(air)\n",
    "len(train)\n",
    "train.columns\n",
    "train_aggr=train.groupby('visit_date',as_index=True,squeeze=True)[\n",
    "    ['visitors','count_observations']].sum()\n",
    "train_aggr.index.name=None\n",
    "train_aggr[train_aggr.index==train.visit_date[0]]\n",
    "train_aggr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modx2 = sm.tsa.statespace.SARIMAX(air.visit_mean, trend='c', exog=hol[:478], order=(2,0,0), seasonal_order=(0,1,1,7))\n",
    "resultsx2 = modx2.fit()\n",
    "print resultsx2.summary()\n",
    "air['forecastx2'] = resultsx2.predict(start=350, end=None, dynamic=True, exog=pd.DataFrame(hol[:]) )\n",
    "air[['visit_mean', 'forecastx2','forecastx']].plot(figsize=(15, 5));\n",
    "plt.vlines(air.index[-1],13,32,color='k');\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);\n",
    "plt.title('RMSLE: %.4f'% mean_squared_log_error(air['forecastx2'],air.visit_mean) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to predict test future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test.iloc[[0,-1]]\n",
    "hol.iloc[[478,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#air.index.get_loc('2017-04-22')+1\n",
    "\n",
    "pred=resultsx2.predict(start=478, end=516, exog=hol[478:])\n",
    "\n",
    "air['forecastx2'] = resultsx2.predict(start=350, end=477, dynamic=True, exog=pd.DataFrame(hol[:]) )\n",
    "air['visit_mean'].plot(figsize=(15, 5));\n",
    "air['forecastx2'][350:].plot();\n",
    "plt.vlines(air.index[-1],13,32,color='k');\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.vlines(hol.query('holiday_flg==1').index,ylim[0],ylim[1],color='k',alpha = 0.3);\n",
    "plt.title('RMSLE: %.4f'% mean_squared_log_error(air['forecastx2'],air.visit_mean) );\n",
    "pred.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
